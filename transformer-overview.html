<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>How Transformers Work – Attention Is All You Need</title>
  <link rel="icon" type="image/png" href="/icon.png" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet" />
  <style>
    body {
      font-family: 'Inter', sans-serif;
      background: #f9f9f9;
      margin: 0;
      color: #333;
    }
    header {
      background: #0f172a;
      color: white;
      padding: 2rem 1rem;
      text-align: center;
      position: relative;
    }
    .language-select {
      position: absolute;
      top: 1rem;
      right: 1rem;
    }
    select {
      padding: 0.25rem;
      font-size: 1rem;
      border-radius: 0.25rem;
    }
    main {
      max-width: 800px;
      margin: 0 auto;
      padding: 2rem 1rem;
    }
    h1 {
      font-size: 2rem;
    }
    p {
      line-height: 1.6;
      margin-bottom: 1rem;
    }
    .nav {
      margin-top: 3rem;
      display: flex;
      justify-content: space-between;
    }
    a {
      color: #2563eb;
      text-decoration: none;
      font-weight: 600;
    }
    footer {
      text-align: center;
      padding: 1rem;
      font-size: 0.9rem;
      color: #64748b;
    }
  </style>
</head>
<body>
  <header>
    <div class="language-select">
      <select id="languageSwitcher">
        <option value="en">English</option>
        <option value="id">Bahasa Indonesia</option>
      </select>
    </div>
    <h1 data-en="How Transformers Work – Attention Is All You Need" data-id="Cara Kerja Transformer – Attention Is All You Need">How Transformers Work – Attention Is All You Need</h1>
  </header>
  <main>
    <p data-en="Transformers revolutionized NLP by replacing recurrence with attention mechanisms. Each word in a sentence attends to every other word, assigning weights to represent relevance." data-id="Transformer merevolusi NLP dengan menggantikan rekursi dengan mekanisme perhatian. Setiap kata dalam kalimat memperhatikan kata lainnya dan memberi bobot untuk menunjukkan relevansi.">Transformers revolutionized NLP by replacing recurrence with attention mechanisms. Each word in a sentence attends to every other word, assigning weights to represent relevance.</p>
<p data-en="The key components include self-attention, multi-head attention, and positional encoding, enabling deep contextual understanding of language." data-id="Komponen kunci termasuk self-attention, multi-head attention, dan positional encoding, yang memungkinkan pemahaman bahasa secara mendalam dan kontekstual.">The key components include self-attention, multi-head attention, and positional encoding, enabling deep contextual understanding of language.</p>
    <div class="nav">
      <a href="ai-revolution.html">&larr; Previous</a>
      <span></span>
    </div>
  </main>
  <footer>
    &copy; 2025 Seven Muslims. | <a href="/index.html">Home</a>
  </footer>
  <script>
    const switcher = document.getElementById('languageSwitcher');
    switcher.addEventListener('change', () => {
      const lang = switcher.value;
      document.querySelectorAll('[data-en]').forEach(el => {
        el.textContent = el.getAttribute(`data-${lang}`);
      });
    });
  </script>
</body>
</html>
